{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset:<br>\n",
    "train_dataset=original training set with no augmentation<br>\n",
    "back_dataset=training set with back-translation<br>\n",
    "aug_dataset=training set with eda-paraphrasing augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv(r'..\\DAIC\\Preprocessed\\train_dataset.csv')\n",
    "back_dataset=pd.read_csv(r'..\\DAIC\\Preprocessed\\back_dataset.csv')\n",
    "aug_dataset=pd.read_csv(r'..\\DAIC\\Preprocessed\\aug_dataset.csv')\n",
    "test_dataset=pd.read_csv(r'..\\DAIC\\Preprocessed\\test_dataset.csv')\n",
    "val_dataset=pd.read_csv(r'..\\DAIC\\Preprocessed\\dev_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the no of datapoints and class balances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The samples in training dataset is:  107 and the distribution is  PHQ8_Binary\n",
      "0    77\n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "The samples in back dataset is:  136 and the distribution is  PHQ8_Binary\n",
      "0    77\n",
      "1    59\n",
      "Name: count, dtype: int64\n",
      "The samples in aug dataset is:  127 and the distribution is  PHQ8_Binary\n",
      "0    77\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "The samples in validation dataset is:  35 and the distribution is  PHQ8_Binary\n",
      "0    23\n",
      "1    12\n",
      "Name: count, dtype: int64\n",
      "The samples in test dataset is:  47 and the distribution is  PHQ8_Binary\n",
      "0    33\n",
      "1    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'The samples in training dataset is: ',(len(train_dataset['response'])),'and the distribution is ',(train_dataset['PHQ8_Binary'].value_counts()))\n",
    "print(f'The samples in back dataset is: ',(len(back_dataset['response'])),'and the distribution is ',(back_dataset['PHQ8_Binary'].value_counts()))\n",
    "print(f'The samples in aug dataset is: ',(len(aug_dataset['response'])),'and the distribution is ',(aug_dataset['PHQ8_Binary'].value_counts()))\n",
    "print(f'The samples in validation dataset is: ',(len(val_dataset['response'])),'and the distribution is ',(val_dataset['PHQ8_Binary'].value_counts()))\n",
    "print(f'The samples in test dataset is: ',(len(test_dataset['response'])),'and the distribution is ',(test_dataset['PHQ8_Binary'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the training dataset. First of all we will do the classification without under/oversampling, using tf-idf, word2vec and glove. After which we will use sampling balancing. We will the test in the validation set and subsequently test set. We will do the same for back and aug dataset. At last we, will also try incorporating val into training dataset, as we have a separate test dataset for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TF-IDF</h1>\n",
    "<h3>Train_set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(lowercase=True,stop_words='english',max_features=6100)\n",
    "\n",
    "X_train_tfidf=tfidf_vectorizer.fit_transform(train_dataset['response'])\n",
    "X_val_tfidf=tfidf_vectorizer.transform(val_dataset['response'])\n",
    "X_test_tfidf=tfidf_vectorizer.transform(test_dataset['response'])\n",
    "\n",
    "y_train=train_dataset['PHQ8_Binary']\n",
    "y_val=val_dataset['PHQ8_Binary']\n",
    "y_test=test_dataset['PHQ8_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.67      0.87      0.75        23\n",
      "  Depression       0.40      0.17      0.24        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.53      0.52      0.50        35\n",
      "weighted avg       0.58      0.63      0.58        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.74      0.94      0.83        33\n",
      "  Depression       0.60      0.21      0.32        14\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.67      0.58      0.57        47\n",
      "weighted avg       0.70      0.72      0.67        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000000.0,random_state=42)\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.83      0.65      0.73        23\n",
      "  Depression       0.53      0.75      0.62        12\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.68      0.70      0.68        35\n",
      "weighted avg       0.73      0.69      0.69        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.87      0.79      0.83        33\n",
      "  Depression       0.59      0.71      0.65        14\n",
      "\n",
      "    accuracy                           0.77        47\n",
      "   macro avg       0.73      0.75      0.74        47\n",
      "weighted avg       0.78      0.77      0.77        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler()\n",
    "X_train_tfidf_un,y_train_un=rus.fit_resample(X_train_tfidf,y_train)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_tfidf_un,y_train_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      1.00      0.81        23\n",
      "  Depression       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.84      0.54      0.48        35\n",
      "weighted avg       0.79      0.69      0.58        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.73      0.97      0.83        33\n",
      "  Depression       0.67      0.14      0.24        14\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.70      0.56      0.53        47\n",
      "weighted avg       0.71      0.72      0.65        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE()\n",
    "X_train_tfidf_smote,y_train_smote=smote.fit_resample(X_train_tfidf,y_train)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100.0,random_state=42)\n",
    "lr.fit(X_train_tfidf_smote,y_train_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Back_Set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(lowercase=True,stop_words='english',max_features=6100)\n",
    "\n",
    "X_back_tfidf=tfidf_vectorizer.fit_transform(back_dataset['response'])\n",
    "X_val_tfidf=tfidf_vectorizer.transform(val_dataset['response'])\n",
    "X_test_tfidf=tfidf_vectorizer.transform(test_dataset['response'])\n",
    "\n",
    "y_back=back_dataset['PHQ8_Binary']\n",
    "y_val=val_dataset['PHQ8_Binary']\n",
    "y_test=test_dataset['PHQ8_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.66      0.83      0.73        23\n",
      "  Depression       0.33      0.17      0.22        12\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.49      0.50      0.48        35\n",
      "weighted avg       0.54      0.60      0.56        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.70      0.91      0.79        33\n",
      "  Depression       0.25      0.07      0.11        14\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.47      0.49      0.45        47\n",
      "weighted avg       0.56      0.66      0.59        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1.0,random_state=42)\n",
    "lr.fit(X_back_tfidf,y_back)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.69      0.96      0.80        23\n",
      "  Depression       0.67      0.17      0.27        12\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.68      0.56      0.53        35\n",
      "weighted avg       0.68      0.69      0.62        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.76      0.94      0.84        33\n",
      "  Depression       0.67      0.29      0.40        14\n",
      "\n",
      "    accuracy                           0.74        47\n",
      "   macro avg       0.71      0.61      0.62        47\n",
      "weighted avg       0.73      0.74      0.71        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler()\n",
    "X_back_tfidf_un,y_back_un=rus.fit_resample(X_back_tfidf,y_back)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_back_tfidf_un,y_back_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.64      0.78      0.71        23\n",
      "  Depression       0.29      0.17      0.21        12\n",
      "\n",
      "    accuracy                           0.57        35\n",
      "   macro avg       0.46      0.47      0.46        35\n",
      "weighted avg       0.52      0.57      0.54        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.70      0.94      0.81        33\n",
      "  Depression       0.33      0.07      0.12        14\n",
      "\n",
      "    accuracy                           0.68        47\n",
      "   macro avg       0.52      0.51      0.46        47\n",
      "weighted avg       0.59      0.68      0.60        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE()\n",
    "X_back_tfidf_smote,y_back_smote=smote.fit_resample(X_back_tfidf,y_back)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1.0,random_state=42)\n",
    "lr.fit(X_back_tfidf_smote,y_back_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Aug_Set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(lowercase=True,stop_words='english',max_features=6200)\n",
    "\n",
    "X_aug_tfidf=tfidf_vectorizer.fit_transform(aug_dataset['response'])\n",
    "X_val_tfidf=tfidf_vectorizer.transform(val_dataset['response'])\n",
    "X_test_tfidf=tfidf_vectorizer.transform(test_dataset['response'])\n",
    "\n",
    "y_aug=aug_dataset['PHQ8_Binary']\n",
    "y_val=val_dataset['PHQ8_Binary']\n",
    "y_test=test_dataset['PHQ8_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.91      0.78        23\n",
      "  Depression       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.59      0.54      0.51        35\n",
      "weighted avg       0.62      0.66      0.60        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.74      0.88      0.81        33\n",
      "  Depression       0.50      0.29      0.36        14\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.62      0.58      0.58        47\n",
      "weighted avg       0.67      0.70      0.67        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "lr.fit(X_aug_tfidf,y_aug)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.74      0.71        23\n",
      "  Depression       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.54      0.54      0.54        35\n",
      "weighted avg       0.58      0.60      0.59        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.80      0.85      0.82        33\n",
      "  Depression       0.58      0.50      0.54        14\n",
      "\n",
      "    accuracy                           0.74        47\n",
      "   macro avg       0.69      0.67      0.68        47\n",
      "weighted avg       0.74      0.74      0.74        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler()\n",
    "X_aug_tfidf_un,y_aug_un=rus.fit_resample(X_aug_tfidf,y_aug)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_aug_tfidf_un,y_aug_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.91      0.78        23\n",
      "  Depression       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.59      0.54      0.51        35\n",
      "weighted avg       0.62      0.66      0.60        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.72      0.88      0.79        33\n",
      "  Depression       0.43      0.21      0.29        14\n",
      "\n",
      "    accuracy                           0.68        47\n",
      "   macro avg       0.58      0.55      0.54        47\n",
      "weighted avg       0.64      0.68      0.64        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE()\n",
    "X_aug_tfidf_smote,y_aug_smote=smote.fit_resample(X_aug_tfidf,y_aug)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "lr.fit(X_aug_tfidf_smote,y_aug_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_tfidf)\n",
    "y_test_pred=lr.predict(X_test_tfidf)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Word2Vec</h1>\n",
    "<h3>Train_set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_path='..\\GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin'\n",
    "word2vec=gensim.models.KeyedVectors.load_word2vec_format(word2vec_path,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list,vector,k=300):\n",
    "    valid_vectors=[vector[word] for word in tokens_list if word in vector]\n",
    "\n",
    "    if not valid_vectors:\n",
    "        print(tokens_list)\n",
    "        return np.zeros(k)\n",
    "        \n",
    "    \n",
    "    return np.mean(valid_vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['tokens']=train_dataset['response'].apply(lambda x:x.split())\n",
    "val_dataset['tokens']=val_dataset['response'].apply(lambda x:x.split())\n",
    "test_dataset['tokens']=test_dataset['response'].apply(lambda x:x.split())\n",
    "X_train_word2vec=np.array([get_average_word2vec(tokens,word2vec) for tokens in train_dataset['tokens'] ])\n",
    "X_val_word2vec=np.array([get_average_word2vec(tokens,word2vec) for tokens in val_dataset['tokens']])\n",
    "X_test_word2vec=np.array([get_average_word2vec(tokens,word2vec) for tokens in test_dataset['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.75      0.65      0.70        23\n",
      "  Depression       0.47      0.58      0.52        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.61      0.62      0.61        35\n",
      "weighted avg       0.65      0.63      0.64        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.85      0.70      0.77        33\n",
      "  Depression       0.50      0.71      0.59        14\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.68      0.71      0.68        47\n",
      "weighted avg       0.75      0.70      0.71        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100.0,random_state=42)\n",
    "lr.fit(X_train_word2vec,y_train)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_train_word2vec_un,y_train_word2vec_un=rus.fit_resample(X_train_word2vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.87      0.57      0.68        23\n",
      "  Depression       0.50      0.83      0.62        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.68      0.70      0.65        35\n",
      "weighted avg       0.74      0.66      0.66        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.84      0.48      0.62        33\n",
      "  Depression       0.39      0.79      0.52        14\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.62      0.64      0.57        47\n",
      "weighted avg       0.71      0.57      0.59        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_train_word2vec_un,y_train_word2vec_un=rus.fit_resample(X_train_word2vec,y_train)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_word2vec_un,y_train_word2vec_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.69      0.78      0.73        23\n",
      "  Depression       0.44      0.33      0.38        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.57      0.56      0.56        35\n",
      "weighted avg       0.61      0.63      0.61        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.79      0.70      0.74        33\n",
      "  Depression       0.44      0.57      0.50        14\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.62      0.63      0.62        47\n",
      "weighted avg       0.69      0.66      0.67        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE(random_state=42)\n",
    "X_train_word2vec_smote,y_train_word2vec_smote=smote.fit_resample(X_train_word2vec,y_train)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "lr.fit(X_train_word2vec_smote,y_train_word2vec_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Back_set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_dataset['tokens']=back_dataset['response'].apply(lambda x:x.split())\n",
    "X_back_word2vec=np.array([get_average_word2vec(tokens,word2vec) for tokens in back_dataset['tokens'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.70      0.83      0.76        23\n",
      "  Depression       0.50      0.33      0.40        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.60      0.58      0.58        35\n",
      "weighted avg       0.63      0.66      0.64        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.74      0.79      0.76        33\n",
      "  Depression       0.42      0.36      0.38        14\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.58      0.57      0.57        47\n",
      "weighted avg       0.65      0.66      0.65        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000.0,random_state=42)\n",
    "lr.fit(X_back_word2vec,y_back)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_back_word2vec_un,y_back_word2vec_un=rus.fit_resample(X_back_word2vec,y_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.83      0.75        23\n",
      "  Depression       0.43      0.25      0.32        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.55      0.54      0.53        35\n",
      "weighted avg       0.59      0.63      0.60        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.69      0.73      0.71        33\n",
      "  Depression       0.25      0.21      0.23        14\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.47      0.47      0.47        47\n",
      "weighted avg       0.56      0.57      0.56        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_back_word2vec_un,y_back_word2vec_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.70      0.83      0.76        23\n",
      "  Depression       0.50      0.33      0.40        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.60      0.58      0.58        35\n",
      "weighted avg       0.63      0.66      0.64        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.74      0.79      0.76        33\n",
      "  Depression       0.42      0.36      0.38        14\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.58      0.57      0.57        47\n",
      "weighted avg       0.65      0.66      0.65        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE(random_state=42)\n",
    "X_back_word2vec_smote,y_back_word2vec_smote=smote.fit_resample(X_back_word2vec,y_back)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "lr.fit(X_back_word2vec_smote,y_back_word2vec_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Aug_set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset['tokens']=aug_dataset['response'].apply(lambda x:x.split())\n",
    "X_aug_word2vec=np.array([get_average_word2vec(tokens,word2vec) for tokens in aug_dataset['tokens'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.70      0.83      0.76        23\n",
      "  Depression       0.50      0.33      0.40        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.60      0.58      0.58        35\n",
      "weighted avg       0.63      0.66      0.64        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.81      0.76      0.78        33\n",
      "  Depression       0.50      0.57      0.53        14\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.65      0.66      0.66        47\n",
      "weighted avg       0.72      0.70      0.71        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000.0,random_state=42)\n",
    "lr.fit(X_aug_word2vec,y_aug)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_aug_word2vec_un,y_aug_word2vec_un=rus.fit_resample(X_aug_word2vec,y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.74      0.74      0.74        23\n",
      "  Depression       0.50      0.50      0.50        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.62      0.62      0.62        35\n",
      "weighted avg       0.66      0.66      0.66        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.85      0.67      0.75        33\n",
      "  Depression       0.48      0.71      0.57        14\n",
      "\n",
      "    accuracy                           0.68        47\n",
      "   macro avg       0.66      0.69      0.66        47\n",
      "weighted avg       0.74      0.68      0.69        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_aug_word2vec_un,y_aug_word2vec_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.65      0.74      0.69        23\n",
      "  Depression       0.33      0.25      0.29        12\n",
      "\n",
      "    accuracy                           0.57        35\n",
      "   macro avg       0.49      0.49      0.49        35\n",
      "weighted avg       0.54      0.57      0.55        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.78      0.76      0.77        33\n",
      "  Depression       0.47      0.50      0.48        14\n",
      "\n",
      "    accuracy                           0.68        47\n",
      "   macro avg       0.62      0.63      0.63        47\n",
      "weighted avg       0.69      0.68      0.68        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE(random_state=42)\n",
    "X_aug_word2vec_smote,y_aug_word2vec_smote=smote.fit_resample(X_aug_word2vec,y_aug)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000000.0,random_state=42)\n",
    "lr.fit(X_aug_word2vec_smote,y_aug_word2vec_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_word2vec)\n",
    "y_test_pred=lr.predict(X_test_word2vec)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GlOvE</h1>\n",
    "<h3>Train_Set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index={}\n",
    "glove_path='../glove.6B.100d.txt'\n",
    "with open(glove_path,'r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        coefs=np.asarray(values[1:],dtype='float32')\n",
    "        embedding_index[word]=coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_glove(tokens_list,embedding_index,k=100):\n",
    "    valid_vectors=[embedding_index[word] for word in tokens_list if word in embedding_index]\n",
    "\n",
    "    if not valid_vectors:\n",
    "        return np.zeros(k)\n",
    "    \n",
    "    return np.mean(valid_vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove=np.array([get_average_glove(tokens,embedding_index) for tokens in train_dataset['tokens']])\n",
    "X_back_glove=np.array([get_average_glove(tokens,embedding_index) for tokens in back_dataset['tokens']])\n",
    "X_aug_glove=np.array([get_average_glove(tokens,embedding_index) for tokens in aug_dataset['tokens']])\n",
    "X_val_glove=np.array([get_average_glove(tokens,embedding_index) for tokens in val_dataset['tokens']])\n",
    "X_test_glove=np.array([get_average_glove(tokens,embedding_index) for tokens in test_dataset['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.74      0.71        23\n",
      "  Depression       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.54      0.54      0.54        35\n",
      "weighted avg       0.58      0.60      0.59        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.82      0.70      0.75        33\n",
      "  Depression       0.47      0.64      0.55        14\n",
      "\n",
      "    accuracy                           0.68        47\n",
      "   macro avg       0.65      0.67      0.65        47\n",
      "weighted avg       0.72      0.68      0.69        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000.0,random_state=42)\n",
    "lr.fit(X_train_glove,y_train)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_train_glove_un,y_train_glove_un=rus.fit_resample(X_train_glove,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.57      0.62        23\n",
      "  Depression       0.38      0.50      0.43        12\n",
      "\n",
      "    accuracy                           0.54        35\n",
      "   macro avg       0.53      0.53      0.52        35\n",
      "weighted avg       0.58      0.54      0.55        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.80      0.61      0.69        33\n",
      "  Depression       0.41      0.64      0.50        14\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.60      0.62      0.59        47\n",
      "weighted avg       0.68      0.62      0.63        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_glove_un,y_train_glove_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.71      0.74      0.72        23\n",
      "  Depression       0.45      0.42      0.43        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.58      0.58      0.58        35\n",
      "weighted avg       0.62      0.63      0.62        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.86      0.73      0.79        33\n",
      "  Depression       0.53      0.71      0.61        14\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.69      0.72      0.70        47\n",
      "weighted avg       0.76      0.72      0.73        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE(random_state=42)\n",
    "X_train_glove_smote,y_train_glove_smote=smote.fit_resample(X_train_glove,y_train)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000000.0,random_state=42)\n",
    "lr.fit(X_train_glove_smote,y_train_glove_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Back_set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.67      0.78      0.72        23\n",
      "  Depression       0.38      0.25      0.30        12\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.52      0.52      0.51        35\n",
      "weighted avg       0.57      0.60      0.58        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.83      0.88      0.85        33\n",
      "  Depression       0.67      0.57      0.62        14\n",
      "\n",
      "    accuracy                           0.79        47\n",
      "   macro avg       0.75      0.73      0.73        47\n",
      "weighted avg       0.78      0.79      0.78        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1000.0,random_state=42)\n",
    "lr.fit(X_back_glove,y_back)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_back_glove_un,y_back_glove_un=rus.fit_resample(X_back_glove,y_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.64      0.70      0.67        23\n",
      "  Depression       0.30      0.25      0.27        12\n",
      "\n",
      "    accuracy                           0.54        35\n",
      "   macro avg       0.47      0.47      0.47        35\n",
      "weighted avg       0.52      0.54      0.53        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.80      0.85      0.82        33\n",
      "  Depression       0.58      0.50      0.54        14\n",
      "\n",
      "    accuracy                           0.74        47\n",
      "   macro avg       0.69      0.67      0.68        47\n",
      "weighted avg       0.74      0.74      0.74        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_back_glove_un,y_back_glove_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.68      0.74      0.71        23\n",
      "  Depression       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.54      0.54      0.54        35\n",
      "weighted avg       0.58      0.60      0.59        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.81      0.79      0.80        33\n",
      "  Depression       0.53      0.57      0.55        14\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.67      0.68      0.68        47\n",
      "weighted avg       0.73      0.72      0.73        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE(random_state=42)\n",
    "X_back_glove_smote,y_back_glove_smote=smote.fit_resample(X_back_glove,y_back)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "lr.fit(X_back_glove_smote,y_back_glove_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Aug_set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.69      0.78      0.73        23\n",
      "  Depression       0.44      0.33      0.38        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.57      0.56      0.56        35\n",
      "weighted avg       0.61      0.63      0.61        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.81      0.79      0.80        33\n",
      "  Depression       0.53      0.57      0.55        14\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.67      0.68      0.68        47\n",
      "weighted avg       0.73      0.72      0.73        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=1000000000.0,random_state=42)\n",
    "lr.fit(X_aug_glove,y_aug)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "rus=RandomUnderSampler(random_state=42)\n",
    "X_aug_glove_un,y_aug_glove_un=rus.fit_resample(X_aug_glove,y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.72      0.78      0.75        23\n",
      "  Depression       0.50      0.42      0.45        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.61      0.60      0.60        35\n",
      "weighted avg       0.64      0.66      0.65        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.89      0.73      0.80        33\n",
      "  Depression       0.55      0.79      0.65        14\n",
      "\n",
      "    accuracy                           0.74        47\n",
      "   macro avg       0.72      0.76      0.72        47\n",
      "weighted avg       0.79      0.74      0.75        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=10000000.0,random_state=42)\n",
    "# lr=LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_aug_glove_un,y_aug_glove_un)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.69      0.78      0.73        23\n",
      "  Depression       0.44      0.33      0.38        12\n",
      "\n",
      "    accuracy                           0.63        35\n",
      "   macro avg       0.57      0.56      0.56        35\n",
      "weighted avg       0.61      0.63      0.61        35\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Controlled       0.81      0.76      0.78        33\n",
      "  Depression       0.50      0.57      0.53        14\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.65      0.66      0.66        47\n",
      "weighted avg       0.72      0.70      0.71        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random OverSampling\n",
    "smote=SMOTE(random_state=42)\n",
    "X_aug_glove_smote,y_aug_glove_smote=smote.fit_resample(X_aug_glove,y_aug)\n",
    "lr=LogisticRegression(max_iter=1000,class_weight='balanced',C=100000.0,random_state=42)\n",
    "lr.fit(X_aug_glove_smote,y_aug_glove_smote)\n",
    "\n",
    "y_val_pred=lr.predict(X_val_glove)\n",
    "y_test_pred=lr.predict(X_test_glove)\n",
    "\n",
    "print('Validation Set Performance:')\n",
    "print(classification_report(y_val,y_val_pred,target_names=['Controlled','Depression'],zero_division=0.0))\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(classification_report(y_test,y_test_pred,target_names=['Controlled','Depression'],zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that word2vec and glove perforrms extremely well without any augmentation and sampling. Their test results are really good, however their validation results aren't that good. It can be that test dataset is more similar in distribution to train dataset than validation dataset. <br>\n",
    "Overall, train_dataset (non-augmented data) with <strong>tf-idf embeddings</strong> and <strong>undersampling</strong> performed the best. The test scores are highest, however the validation scores are highest as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
