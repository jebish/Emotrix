{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook preprocesses the dataset for classification task using classical and sequential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set=pd.read_csv(r'DAIC\\dev_split_Depression_AVEC2017.csv')\n",
    "train_set=pd.read_csv(r'DAIC\\train_split_Depression_AVEC2017.csv')\n",
    "test_set=pd.read_csv(r'DAIC\\full_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id=train_set['Participant_ID']\n",
    "dev_id=dev_set['Participant_ID']\n",
    "test_id=test_set['Participant_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if train, dev and test set contains same participant (i.e. data leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in train_id:\n",
    "    if id in test_id:\n",
    "        print(id)\n",
    "    if id in dev_id:\n",
    "        print(id)\n",
    "\n",
    "for id in test_id:\n",
    "    if id in dev_id:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total no. of data in train set, test set, dev set and total set is 107, 47, 35 and 189.\n"
     ]
    }
   ],
   "source": [
    "print(f'The total no. of data in train set, test set, dev set and total set is {len(train_id)}, {len(test_id)}, {len(dev_id)} and {len(train_id)+len(test_id)+len(dev_id)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a new csv file for interviewees' response, their scores and participation ID for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold='DAIC\\DAIC_text\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data={\n",
    "    'Participant_ID':[],\n",
    "    'response':[],\n",
    "    'PHQ8_Binary':[],\n",
    "    'PHQ8_Score':[],\n",
    "    'PHQ8_NoInterest':[],\n",
    "    'PHQ8_Depressed':[],\n",
    "    'PHQ8_Sleep':[],\n",
    "    'PHQ8_Tired':[],\n",
    "    'PHQ8_Appetite':[],\n",
    "    'PHQ8_Failure':[]\n",
    "    }\n",
    "for id in train_id:\n",
    "    data=pd.read_csv(fold+str(id)+'_TRANSCRIPT.CSV',sep='\\t')\n",
    "    response=data.loc[data.speaker=='Participant','value']\n",
    "    resp=' '.join(str(respo) for respo in response) \n",
    "    train_data['Participant_ID'].append(id)\n",
    "    train_data['response'].append(resp)\n",
    "    train_data['PHQ8_Binary'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Binary'].values[0])\n",
    "    train_data['PHQ8_Score'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Score'].values[0])\n",
    "    train_data['PHQ8_NoInterest'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_NoInterest'].values[0])\n",
    "    train_data['PHQ8_Depressed'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Depressed'].values[0])\n",
    "    train_data['PHQ8_Sleep'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Sleep'].values[0])\n",
    "    train_data['PHQ8_Tired'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Tired'].values[0])\n",
    "    train_data['PHQ8_Appetite'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Appetite'].values[0])\n",
    "    train_data['PHQ8_Failure'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Failure'].values[0])\n",
    "\n",
    "train_dataset=pd.DataFrame.from_dict(train_data,orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data={\n",
    "    'Participant_ID':[],\n",
    "    'response':[],\n",
    "    'PHQ8_Binary':[],\n",
    "    'PHQ8_Score':[],\n",
    "    'PHQ8_NoInterest':[],\n",
    "    'PHQ8_Depressed':[],\n",
    "    'PHQ8_Sleep':[],\n",
    "    'PHQ8_Tired':[],\n",
    "    'PHQ8_Appetite':[],\n",
    "    'PHQ8_Failure':[]\n",
    "    }\n",
    "for id in train_id:\n",
    "    data=pd.read_csv(fold+str(id)+'_TRANSCRIPT.CSV',sep='\\t')\n",
    "    response=data.loc[data.speaker=='Participant','value']\n",
    "    resp='. '.join(str(respo) for respo in response) \n",
    "    aug_data['Participant_ID'].append(id)\n",
    "    aug_data['response'].append(resp)\n",
    "    aug_data['PHQ8_Binary'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Binary'].values[0])\n",
    "    aug_data['PHQ8_Score'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Score'].values[0])\n",
    "    aug_data['PHQ8_NoInterest'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_NoInterest'].values[0])\n",
    "    aug_data['PHQ8_Depressed'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Depressed'].values[0])\n",
    "    aug_data['PHQ8_Sleep'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Sleep'].values[0])\n",
    "    aug_data['PHQ8_Tired'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Tired'].values[0])\n",
    "    aug_data['PHQ8_Appetite'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Appetite'].values[0])\n",
    "    aug_data['PHQ8_Failure'].append(train_set.loc[train_set.Participant_ID==id,'PHQ8_Failure'].values[0])\n",
    "\n",
    "aug_dataset=pd.DataFrame.from_dict(aug_data,orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data={\n",
    "    'Participant_ID':[],\n",
    "    'response':[],\n",
    "    'PHQ8_Binary':[],\n",
    "    'PHQ8_Score':[],\n",
    "    'PHQ8_NoInterest':[],\n",
    "    'PHQ8_Depressed':[],\n",
    "    'PHQ8_Sleep':[],\n",
    "    'PHQ8_Tired':[],\n",
    "    'PHQ8_Appetite':[],\n",
    "    'PHQ8_Failure':[]\n",
    "    }\n",
    "for id in dev_id:\n",
    "    data=pd.read_csv(fold+str(id)+'_TRANSCRIPT.CSV',sep='\\t')\n",
    "    response=data.loc[data.speaker=='Participant','value']\n",
    "    resp=' '.join(str(respo) for respo in response) \n",
    "    dev_data['Participant_ID'].append(id)\n",
    "    dev_data['response'].append(resp)\n",
    "    dev_data['PHQ8_Binary'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Binary'].values[0])\n",
    "    dev_data['PHQ8_Score'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Score'].values[0])\n",
    "    dev_data['PHQ8_NoInterest'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_NoInterest'].values[0])\n",
    "    dev_data['PHQ8_Depressed'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Depressed'].values[0])\n",
    "    dev_data['PHQ8_Sleep'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Sleep'].values[0])\n",
    "    dev_data['PHQ8_Tired'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Tired'].values[0])\n",
    "    dev_data['PHQ8_Appetite'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Appetite'].values[0])\n",
    "    dev_data['PHQ8_Failure'].append(dev_set.loc[dev_set.Participant_ID==id,'PHQ8_Failure'].values[0])\n",
    "\n",
    "dev_dataset=pd.DataFrame.from_dict(dev_data,orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data={\n",
    "    'Participant_ID':[],\n",
    "    'response':[],\n",
    "    'PHQ8_Binary':[],\n",
    "    'PHQ8_Score':[]\n",
    "    }\n",
    "for id in test_id:\n",
    "    data=pd.read_csv(fold+str(id)+'_TRANSCRIPT.CSV',sep='\\t')\n",
    "    response=data.loc[data.speaker=='Participant','value']\n",
    "    resp=' '.join(str(respo) for respo in response) \n",
    "    test_data['Participant_ID'].append(id)\n",
    "    test_data['response'].append(resp)\n",
    "    test_data['PHQ8_Binary'].append(test_set.loc[test_set.Participant_ID==id,'PHQ_Binary'].values[0])\n",
    "    test_data['PHQ8_Score'].append(test_set.loc[test_set.Participant_ID==id,'PHQ_Score'].values[0])\n",
    "\n",
    "test_dataset=pd.DataFrame.from_dict(test_data,orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('DAIC\\\\train_dataset.csv')\n",
    "dev_dataset.to_csv('DAIC\\\\dev_dataset.csv')\n",
    "test_dataset.to_csv('DAIC\\\\test_dataset.csv')\n",
    "aug_dataset.to_csv('DAIC\\\\aug_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start text-preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv('DAIC\\\\train_dataset.csv')\n",
    "aug_dataset=pd.read_csv(r'DAIC\\Preprocessed\\aug_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_dataset.shape[0]):\n",
    "    print(train_dataset['response'][i])\n",
    "    train_dataset['response'][i]=train_dataset['response'][i].replace('um','')\n",
    "    train_dataset['response'][i]=train_dataset['response'][i].replace('<sync>','')\n",
    "    train_dataset['response'][i]=train_dataset['response'][i].replace('<synch>','')\n",
    "    train_dataset['response'][i]=train_dataset['response'][i].replace('  ',' ')\n",
    "    train_dataset['response'][i]=re.sub(r\"<(\\w*)>\",r\"\\1\",train_dataset['response'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_dataset.shape[0]):\n",
    "    print(test_dataset['response'][i])\n",
    "    test_dataset['response'][i]=test_dataset['response'][i].replace('um','')\n",
    "    test_dataset['response'][i]=test_dataset['response'][i].replace('<sync>','')\n",
    "    test_dataset['response'][i]=test_dataset['response'][i].replace('<synch>','')\n",
    "    test_dataset['response'][i]=test_dataset['response'][i].replace('  ',' ')\n",
    "    test_dataset['response'][i]=re.sub(r\"<(\\w*)>\",r\"\\1\",test_dataset['response'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dev_dataset.shape[0]):\n",
    "    print(dev_dataset['response'][i])\n",
    "    dev_dataset['response'][i]=dev_dataset['response'][i].replace('um','')\n",
    "    dev_dataset['response'][i]=dev_dataset['response'][i].replace('<sync>','')\n",
    "    dev_dataset['response'][i]=dev_dataset['response'][i].replace('<synch>','')\n",
    "    dev_dataset['response'][i]=dev_dataset['response'][i].replace('  ',' ')\n",
    "    dev_dataset['response'][i]=re.sub(r\"<(\\w*)>\",r\"\\1\",dev_dataset['response'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(aug_dataset.shape[0]):\n",
    "    print(aug_dataset['response'][i])\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace('.','')\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].lower()\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace(',','')\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace('\\n',' ')\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace('um','')\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace('<sync>','')\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace('<synch>','')\n",
    "    aug_dataset['response'][i]=aug_dataset['response'][i].replace('  ',' ')\n",
    "    aug_dataset['response'][i]=re.sub(r\"<(\\w*)>\",r\"\\1\",aug_dataset['response'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('DAIC\\\\Preprocessed\\\\train_dataset.csv')\n",
    "dev_dataset.to_csv('DAIC\\\\Preprocessed\\\\dev_dataset.csv')\n",
    "test_dataset.to_csv('DAIC\\\\Preprocessed\\\\test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = aug_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "shuffled_df.to_csv('DAIC\\\\Preprocessed\\\\aug_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
